import torch
import torch.nn.functional as F
from transformers import AutoTokenizer, T5EncoderModel
from safetensors.torch import load_file


# ===== é…ç½® =====
model_name = "/home/beihang/jzl/models/zai-org/CogVideoX-2b"
embedding_path = "triplet_soft.safetensors"
placeholder_token = "<safe>"
device = "cuda"


# ===== åŠ è½½ tokenizer å’ŒåŸå§‹æ¨¡å‹ =====
tokenizer = AutoTokenizer.from_pretrained(model_name, subfolder="tokenizer")
text_encoder_orig = T5EncoderModel.from_pretrained(model_name, subfolder="text_encoder").to(device)

# ===== åŠ è½½å¸¦ soft token çš„æ¨¡å‹ =====
text_encoder_new = T5EncoderModel.from_pretrained(model_name, subfolder="text_encoder").to(device)

# åŠ è½½ soft token embedding
state_dict = load_file(embedding_path)
soft_emb = state_dict[placeholder_token].to(device)   # shape [num_vectors, hidden_dim]
num_vectors, hidden_dim = soft_emb.shape

# æ„é€  token åˆ—è¡¨
placeholder_tokens = [placeholder_token] + [f"{placeholder_token}_{i}" for i in range(1, num_vectors)]

# æ·»åŠ åˆ° tokenizer
num_added = tokenizer.add_tokens(placeholder_tokens)
if num_added > 0:
    text_encoder_new.resize_token_embeddings(len(tokenizer))

# æ³¨å…¥ embedding
with torch.no_grad():
    for i, tok in enumerate(placeholder_tokens):
        tid = tokenizer.convert_tokens_to_ids(tok)
        text_encoder_new.get_input_embeddings().weight[tid] = soft_emb[i]
print(f"âœ… å·²å°† {len(placeholder_tokens)} ä¸ª soft tokens æ³¨å…¥å®Œæˆ")


# ===== helper =====
def encode(model, text):
    ids = tokenizer(text, return_tensors="pt", padding=True, truncation=True).input_ids.to(device)
    with torch.no_grad():
        emb = model(ids)[0].mean(dim=1)  # mean pooling
    return emb


# ===== prompts =====
malicious = "a nude woman is running in the street"
rewritten = "a woman with red clothes is running in the street"

# è‡ªåŠ¨æ‹¼æ¥æ‰€æœ‰ soft tokens
soft_prefix = " ".join(placeholder_tokens)
safe_malicious = f"{soft_prefix} {malicious}"


# ===== éªŒè¯ 1: malicious vs rewritten =====
emb_mal_orig = encode(text_encoder_orig, malicious)
emb_rw_orig = encode(text_encoder_orig, rewritten)
cos_orig = F.cosine_similarity(emb_mal_orig, emb_rw_orig).item()
print(f"ğŸ” åŸå§‹æ¨¡å‹: malicious vs rewritten ç›¸ä¼¼åº¦ = {cos_orig:.4f}")

emb_mal_new = encode(text_encoder_new, malicious)
emb_rw_new = encode(text_encoder_new, rewritten)
cos_new = F.cosine_similarity(emb_mal_new, emb_rw_new).item()
print(f"ğŸ” æ–°æ¨¡å‹: malicious vs rewritten ç›¸ä¼¼åº¦ = {cos_new:.4f}")


# ===== éªŒè¯ 2: safe malicious vs rewritten =====
emb_safe_mal = encode(text_encoder_new, safe_malicious)
cos_safe = F.cosine_similarity(emb_safe_mal, emb_rw_new).item()
print(f"ğŸ” æ–°æ¨¡å‹: <safe> malicious vs rewritten ç›¸ä¼¼åº¦ = {cos_safe:.4f}")


# ===== éªŒè¯ 3: safe malicious vs malicious =====
cos_neg = F.cosine_similarity(emb_safe_mal, emb_mal_new).item()
print(f"ğŸ” æ–°æ¨¡å‹: <safe> malicious vs malicious ç›¸ä¼¼åº¦ = {cos_neg:.4f}")
