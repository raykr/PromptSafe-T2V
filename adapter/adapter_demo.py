import argparse
import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import math
from transformers import AutoTokenizer, T5EncoderModel
from torch.utils.data import Dataset, DataLoader
from tqdm import tqdm
from diffusers import CogVideoXPipeline, CogVideoXDPMScheduler
import pandas as pd
from diffusers.utils import export_to_video

from classifier import PromptSafetyClassifier

class SafeAdapter(nn.Module):
    """
    å†»ç»“ T5 è¾“å‡ºåï¼Œåšä¸€ä¸ªå°ç“¶é¢ˆ + æ®‹å·®çš„å®‰å…¨æ˜ å°„å±‚
    H_safe = H + gate * scale * MLP(LN(H))
    å…¶ä¸­ scale ç”±å¤–éƒ¨åŠ¨æ€æ§åˆ¶ï¼ˆä¾‹å¦‚æ¥è‡ª prompt åˆ†ç±»å™¨ï¼‰
    """

    def __init__(self, hidden_size: int, rank: int = 256, init_gate: float = 0.5):
        super().__init__()
        self.ln = nn.LayerNorm(hidden_size)
        self.down = nn.Linear(hidden_size, rank, bias=False)
        self.up = nn.Linear(rank, hidden_size, bias=False)
        self.act = nn.GELU()
        # å¯å­¦ä¹  base gate
        self.gate = nn.Parameter(torch.tensor(init_gate))

        # å°åˆå§‹åŒ–ï¼Œé¿å…ä¸€å¼€å§‹ç ´ååˆ†å¸ƒ
        nn.init.kaiming_uniform_(self.down.weight, a=math.sqrt(5))
        nn.init.zeros_(self.up.weight)

    def forward(self, hidden_states: torch.Tensor, scale: torch.Tensor | float = 1.0):
        """
        scale: åŠ¨æ€é˜²å¾¡å¼ºåº¦ç³»æ•°
          - å¯ä»¥æ˜¯æ ‡é‡ float
          - ä¹Ÿå¯ä»¥æ˜¯ [B] æˆ– [B, 1, 1] çš„ Tensorï¼ˆä¼šè‡ªåŠ¨å¹¿æ’­ï¼‰
        """
        x = self.ln(hidden_states)
        delta = self.up(self.act(self.down(x)))  # [B, L, D]

        gate = self.gate
        if not torch.is_tensor(scale):
            scale = torch.tensor(scale, device=hidden_states.device, dtype=hidden_states.dtype)
        # scale å½¢çŠ¶è°ƒæ•´ä¸º [B, 1, 1] æˆ– [1, 1, 1]ï¼Œæ–¹ä¾¿å¹¿æ’­
        while scale.dim() < hidden_states.dim():
            scale = scale.unsqueeze(-1)

        eff_gate = gate * scale  # [B,1,1] or [1,1,1]

        return hidden_states + eff_gate * delta


class TemporalSafeAdapter(nn.Module):
    """
    å¯¹ SafeAdapter åŠ å…¥æ—¶åºé—¨æ§ï¼šgate -> gate(Ï„)
    Ï„ âˆˆ [0, 1] ä¸ºå¸§å½’ä¸€åŒ–ç´¢å¼•
    """
    def __init__(self, hidden_size, rank=256, init_gate=0.5, gamma_min=0.5, gamma_max=1.5):
        super().__init__()
        self.ln = nn.LayerNorm(hidden_size)
        self.down = nn.Linear(hidden_size, rank, bias=False)
        self.up = nn.Linear(rank, hidden_size, bias=False)
        self.act = nn.GELU()

        # learnable base gate (scalar)
        self.base_gate = nn.Parameter(torch.tensor(init_gate))

        # temporal controllerï¼ˆå¯å­¦ä¹ æ—¶é—´å‡½æ•°ï¼‰
        self.time_mlp = nn.Sequential(
            nn.Linear(1, 16),
            nn.SiLU(),
            nn.Linear(16, 1),
        )
        self.gamma_min, self.gamma_max = gamma_min, gamma_max

        nn.init.kaiming_uniform_(self.down.weight, a=math.sqrt(5))
        nn.init.zeros_(self.up.weight)

    def forward(self, hidden_states: torch.Tensor, tau: float = 0.0):
        """
        tau: å½“å‰å¸§å½’ä¸€åŒ–æ—¶é—´ (0 ~ 1)
        """
        x = self.ln(hidden_states)
        delta = self.up(self.act(self.down(x)))

        # æ ¹æ®å¸§ç´¢å¼•è°ƒèŠ‚ gate
        tau_tensor = torch.tensor([[tau]], device=hidden_states.device, dtype=hidden_states.dtype)
        gamma = torch.sigmoid(self.time_mlp(tau_tensor))  # (0,1)
        gamma = self.gamma_min + (self.gamma_max - self.gamma_min) * gamma
        gate = self.base_gate * gamma

        return hidden_states + gate * delta



class WrappedTextEncoder(nn.Module):
    def __init__(self, t5_encoder: nn.Module, adapter: SafeAdapter):
        super().__init__()
        self.t5 = t5_encoder
        for p in self.t5.parameters():
            p.requires_grad_(False)
        self.adapter = adapter

        # é»˜è®¤åŠ¨æ€ scale = 1.0ï¼Œå¯ä»¥åœ¨æ¨ç†å‰ç”±å¤–éƒ¨ä¿®æ”¹
        self.adapter_scale = 1.0

    # ğŸ”§ å¯¹å¤–æš´éœ²ä¸€ä¸ªè®¾ç½®æ¥å£ï¼Œæ–¹ä¾¿åœ¨ç”Ÿæˆå‰æ ¹æ® prompt åˆ†ç±»ç»“æœåŠ¨æ€è°ƒèŠ‚
    def set_adapter_scale(self, scale: torch.Tensor | float):
        """
        scale å¯ä»¥æ˜¯:
          - float æ ‡é‡ï¼šå¯¹å½“å‰ batch ä½¿ç”¨ç»Ÿä¸€é˜²å¾¡å¼ºåº¦
          - [B] Tensorï¼šå¯¹ batch å†…æ¯ä¸ªæ ·æœ¬ç”¨ä¸åŒå¼ºåº¦
        """
        self.adapter_scale = scale

    # diffusers çš„ pipeline.to() ä¼šè¯»å–è¿™äº›å±æ€§
    @property
    def dtype(self):
        try:
            return next(self.parameters()).dtype
        except StopIteration:
            return torch.float32

    @property
    def device(self):
        try:
            return next(self.parameters()).device
        except StopIteration:
            return torch.device("cpu")

    def forward(self, input_ids=None, attention_mask=None, inputs_embeds=None, **kwargs):
        outputs = self.t5(
            input_ids=input_ids,
            attention_mask=attention_mask,
            inputs_embeds=inputs_embeds,
            output_hidden_states=False,
            return_dict=True,
        )
        hs = outputs.last_hidden_state  # [B, L, D]
        # å°†å½“å‰å¯¹è±¡çš„ adapter_scale ä¼ ç»™ adapter
        hs_safe = self.adapter(hs, scale=self.adapter_scale)
        outputs.last_hidden_state = hs_safe
        return outputs


class PairDataset(Dataset):
    # items: (malicious, rewritten, benign)
    def __init__(self, csv_path):
        # prompt, rewritten_prompt, benign_prompt -> malicious, rewritten, benign
        self.data = pd.read_csv(csv_path)
        # ç›´æ¥ä½¿ç”¨DataFrameçš„åˆ—ï¼Œä¸éœ€è¦è½¬ç½®
        self.malicious = self.data['prompt'].tolist()
        self.rewritten = self.data['rewritten_prompt'].tolist()
        self.benign = self.data['benign_prompt'].tolist()
        print(f"Loaded {len(self.malicious)} samples")

    def __len__(self):
        return len(self.malicious)

    def __getitem__(self, i):
        return {
            "malicious": self.malicious[i], 
            "rewritten": self.rewritten[i], 
            "benign": self.benign[i]
        }


class SafeAdapterTrainer:
    def __init__(self, model_path, hidden_size=4096, rank=256, lr=5e-4, device="cuda", use_benign=False):
        self.device = device
        self.tokenizer = AutoTokenizer.from_pretrained(model_path, subfolder="tokenizer")
        base = T5EncoderModel.from_pretrained(model_path, subfolder="text_encoder").to(device)
        adapter = SafeAdapter(hidden_size, rank)
        self.model = WrappedTextEncoder(base, adapter).to(device)
        self.opt = torch.optim.AdamW(self.model.adapter.parameters(), lr=lr)
        self.use_benign = use_benign

    def _encode(self, texts):
        batch = self.tokenizer(texts, padding=True, truncation=True, return_tensors="pt").to(self.device)
        with torch.no_grad():  # åªå¯¹ adapter æ±‚æ¢¯åº¦
            out = self.model.t5(**batch).last_hidden_state
        # adapter å‚ä¸æ¢¯åº¦ï¼›è®­ç»ƒé˜¶æ®µ scale å›ºå®šä¸º 1.0
        out = self.model.adapter(out, scale=1.0)  # [B, L, D]
        sent = out.mean(dim=1)  # ç®€å•å¥å‘é‡æ± åŒ–
        return sent

    def step(self, m_list, r_list, b_list=None, margin=0.3, lam_benign=0.1):
        # Anchor = adapter(T5(malicious)), Positive = T5(rewritten) ç» adapter
        # æ³¨æ„ï¼šæ­£æ ·æœ¬ä¹Ÿè¿‡ adapterï¼Œé€‚é…å™¨å­¦â€œæ•´ä½“åˆ†å¸ƒâ€æ˜ å°„æ›´ç¨³
        a = self._encode(m_list)
        p = self._encode(r_list)
        n = self._encode(m_list)  # malicious æœ¬èº«ä½œ negativeï¼ˆä¸åŠ  <safe>ï¼‰

        d_ap = F.pairwise_distance(a, p)
        d_an = F.pairwise_distance(a, n)
        triplet = torch.relu(d_ap - d_an + margin).mean()

        if self.use_benign:
            b0 = self._encode(b_list)  # benign è¿‡ adapter å‰åå°½é‡ä¸å˜ï¼ˆadapter å·²ç»åœ¨ _encode å†…ï¼‰
            # ä¸ºäº†åšâ€œæ’ç­‰çº¦æŸâ€ï¼Œå†è·‘ä¸€éâ€œå†»ç»“ adapterâ€çš„ç‰ˆæœ¬è·å–ç›®æ ‡
            with torch.no_grad():
                batch_b = self.tokenizer(b_list, padding=True, truncation=True, return_tensors="pt").to(self.device)
                b_ref = self.model.t5(**batch_b).last_hidden_state.mean(dim=1)
            benign_cons = F.mse_loss(b0, b_ref)
        else:
            benign_cons = torch.tensor(0.0, device=self.device)

        loss = triplet + lam_benign * benign_cons

        self.opt.zero_grad()
        loss.backward()
        self.opt.step()

        return {
            "loss": loss.item(),
            "triplet": triplet.item(),
            "benign": benign_cons.item(),
            "d_ap": d_ap.mean().item(),
            "d_an": d_an.mean().item(),
        }


def train_adapter(args):
    trainer = SafeAdapterTrainer(
        model_path=args.model_path,
        hidden_size=args.hidden_size, rank=args.rank, lr=args.lr, device=args.device, use_benign=args.use_benign
    )
    loader = DataLoader(PairDataset(args.trainset_path), batch_size=args.batch_size, shuffle=True)
    for epoch in range(args.num_epochs):
        pbar = tqdm(loader, desc=f"Epoch {epoch+1}/{args.num_epochs}", dynamic_ncols=True, leave=False)
        for batch in pbar:
            logs = trainer.step(
                batch["malicious"], batch["rewritten"], batch["benign"],
                margin=args.margin, lam_benign=args.lam_benign
            )
            # åœ¨è¿›åº¦æ¡å°¾éƒ¨å±•ç¤ºå…³é”®æŒ‡æ ‡ï¼Œé¿å…æ‰“æ–­è¿›åº¦æ¡
            pbar.set_postfix({
                "loss": f"{logs['loss']:.3f}",
                "triplet": f"{logs['triplet']:.3f}",
                "benign": f"{logs['benign']:.3f}",
            })

        # æŒ‰é—´éš”ä¿å­˜ checkpoint
        if hasattr(args, "save_every") and args.save_every and (epoch + 1) % args.save_every == 0:
            os.makedirs(os.path.dirname(args.adapter_path), exist_ok=True)
            ckpt_path = args.adapter_path.replace('.pt', f"_epoch{epoch+1}.pt")
            torch.save(trainer.model.adapter.state_dict(), ckpt_path)
            print(f"âœ… å‘¨æœŸæ€§ä¿å­˜: {ckpt_path}")
    torch.save(trainer.model.adapter.state_dict(), args.adapter_path)
    print(f"âœ… SafeAdapter å·²ä¿å­˜åˆ° {args.adapter_path}")


def inject_safe_adapter(pipe, adapter_path, rank=256, hidden_size=4096):
    # 1) æ„å»ºå¹¶åŠ è½½ Adapter
    adapter = SafeAdapter(hidden_size, rank)
    sd = torch.load(adapter_path, map_location="cpu")
    adapter.load_state_dict(sd)

    # 2) åŒ…è£…åŸå§‹ text_encoder
    wrapped = WrappedTextEncoder(pipe.text_encoder, adapter)

    # 3) å…ˆæ”¾åˆ°ä¸ pipeline ä¸€è‡´çš„ dtype/deviceï¼ˆå¸¸è§ float16 + cudaï¼‰
    wrapped = wrapped.to(device=pipe.device, dtype=getattr(pipe.text_encoder, "dtype", torch.float16))

    # 4) æ›¿æ¢å¹¶â€œæ­£è§„â€æ³¨å†Œåˆ° pipeline
    pipe.text_encoder = wrapped
    components = pipe.components.copy()
    components["text_encoder"] = pipe.text_encoder
    pipe.register_modules(**components)

    # 5) å†ç»Ÿä¸€åˆ° cudaï¼ˆæœ‰äº›æ¨¡å—å¯èƒ½è¢« register é‡ç½®äº† deviceï¼‰
    pipe.to(pipe.device)

    print("âœ… SafeAdapter å·²æ³¨å…¥åˆ° pipeline.text_encoder å¹¶å®Œæˆé‡æ–°æ³¨å†Œ/å¯¹é½")
    return pipe


def load_prompt_classifier(args):
    """
    ä» ckpt åŠ è½½ PromptSafetyClassifierï¼Œè¿”å› (classifier, tokenizer, label_cols)
    """
    device = args.device
    state = torch.load(args.cls_ckpt_path, map_location="cpu")
    label_cols = state["label_cols"]

    tokenizer = AutoTokenizer.from_pretrained(args.model_path, subfolder="tokenizer")
    base = T5EncoderModel.from_pretrained(args.model_path, subfolder="text_encoder").to(device)

    model = PromptSafetyClassifier(
        t5_encoder=base,
        hidden_size=args.hidden_size,
        num_labels=len(label_cols),
    ).to(device)
    model.load_state_dict(state["state_dict"])
    model.eval()

    return model, tokenizer, label_cols


@torch.no_grad()
def compute_severity(probs: torch.Tensor) -> torch.Tensor:
    """
    ä¸€ä¸ªç®€å•çš„ severity å®šä¹‰ç¤ºä¾‹ï¼š
      - probs: [B, num_labels]
      - è¿”å› severity: [B] âˆˆ [0,1]
    è¿™é‡Œç›´æ¥å–æ‰€æœ‰ç±»åˆ«æ¦‚ç‡çš„ max ä½œä¸ºæ•´ä½“æœ‰å®³ç¨‹åº¦ï¼Œä½ å¯ä»¥æ ¹æ®éœ€è¦æ”¹æˆåŠ æƒå’Œç­‰ã€‚
    """
    severity, _ = probs.max(dim=-1)
    return severity  # [B]

def eval_adapter(args):
    # 1) åŸå§‹ï¼ˆæœªæ³¨å…¥ï¼‰pipeline
    pipe_raw = CogVideoXPipeline.from_pretrained(args.model_path, torch_dtype=torch.float16)
    pipe_raw.scheduler = CogVideoXDPMScheduler.from_config(pipe_raw.scheduler.config, timestep_spacing="trailing")
    pipe_raw.to(args.device)
    pipe_raw.vae.enable_slicing()
    pipe_raw.vae.enable_tiling()

    # 2) æ³¨å…¥ SafeAdapter çš„ pipeline
    pipe_safe = CogVideoXPipeline.from_pretrained(args.model_path, torch_dtype=torch.float16)
    pipe_safe.scheduler = CogVideoXDPMScheduler.from_config(pipe_safe.scheduler.config, timestep_spacing="trailing")
    pipe_safe.to(args.device)
    pipe_safe.vae.enable_slicing()
    pipe_safe.vae.enable_tiling()
    pipe_safe = inject_safe_adapter(pipe_safe, args.adapter_path, args.rank, args.hidden_size)

    # 3) åŠ è½½ prompt åˆ†ç±»å™¨ï¼ˆç”¨äºåŠ¨æ€è·¯ç”±/å¼ºåº¦æ§åˆ¶ï¼‰
    cls_model, cls_tokenizer, cls_label_cols = load_prompt_classifier(args)

    if not os.path.exists(args.output_dir):
        os.makedirs(args.output_dir)

    # ä» testset_path ä¸­è¯»å– prompts
    data = pd.read_csv(args.testset_path)
    prompts = data["prompt"].tolist()
    for i, prompt in enumerate(prompts):
        # ---- 3.1 å…ˆç”¨åˆ†ç±»å™¨é¢„æµ‹è¯¥ prompt çš„å„ç±»é£é™©æ¦‚ç‡ ----
        tok = cls_tokenizer([prompt], padding=True, truncation=True, return_tensors="pt").to(args.device)
        logits = cls_model(tok["input_ids"], tok["attention_mask"])    # [1,num_labels]
        probs = torch.sigmoid(logits)                                  # [1,num_labels]

        severity = compute_severity(probs)[0].item()  # æ ‡é‡ âˆˆ [0,1]
        # ä½ å¯ä»¥æ ¹æ®éœ€è¦å¯¹ severity åšä¸€ä¸ªæ˜ å°„ï¼Œæ¯”å¦‚:
        #   scale = 0.2 + 0.8 * severity
        # ä»£è¡¨æœ€ä½ 0.2 å¼ºåº¦ï¼Œæœ€é«˜ 1.0 å¼ºåº¦
        scale = 0.2 + 0.8 * severity

        # å°†åŠ¨æ€ scale å†™å…¥ text_encoder
        if hasattr(pipe_safe.text_encoder, "set_adapter_scale"):
            pipe_safe.text_encoder.set_adapter_scale(scale)
        else:
            # å…¼å®¹æ€§ï¼šæ—§ç‰ˆå¯ä»¥ç›´æ¥å†™å±æ€§
            pipe_safe.text_encoder.adapter_scale = scale

        print(f"[{i:03d}] prompt = {prompt[:40]}..., severity = {severity:.3f}, scale = {scale:.3f}")

        # ---- 4) ç”Ÿæˆæœªæ³¨å…¥ï¼ˆrawï¼‰ ----
        video_raw = pipe_raw(
            prompt=prompt,
            num_frames=args.num_frames,
            height=args.height,
            width=args.width,
            num_inference_steps=args.num_inference_steps,
            guidance_scale=args.guidance_scale,
        ).frames[0]
        export_to_video(video_raw, f"{args.output_dir}/adapter_{i:03d}_raw.mp4", fps=args.fps)
        print(f"âœ… è§†é¢‘å·²ä¿å­˜åˆ° {args.output_dir}/adapter_{i:03d}_raw.mp4")

        # ---- 5) ç”Ÿæˆå·²æ³¨å…¥ï¼ˆsafeï¼ŒåŠ¨æ€å¼ºåº¦ï¼‰----
        video_safe = pipe_safe(
            prompt=prompt,
            num_frames=args.num_frames,
            height=args.height,
            width=args.width,
            num_inference_steps=args.num_inference_steps,
            guidance_scale=args.guidance_scale,
        ).frames[0]
        export_to_video(video_safe, f"{args.output_dir}/adapter_{i:03d}_safe.mp4", fps=args.fps)
        print(f"âœ… è§†é¢‘å·²ä¿å­˜åˆ° {args.output_dir}/adapter_{i:03d}_safe.mp4")



if __name__ == "__main__":
    cfg = {
        "model_path": "/home/beihang/jzl/models/zai-org/CogVideoX-5b",
        "hidden_size": 4096,
        "rank": 256,
        "lr": 5e-4,
        "device": "cuda",
        "num_epochs": 100,
        "batch_size": 8,
        "margin": 0.1,
        "lam_benign": 0.1,
        "adapter_path": "checkpoints/4/safe_adapter.pt",
        "cls_ckpt_path": "checkpoints/prompt_classifier.pt",
        "trainset_path": "datasets/train/4.csv",
        "testset_path": "datasets/train/4.csv",
        "output_dir": "out/4_cls",
        "num_frames": 81,
        "height": 480,
        "width": 720,
        "num_inference_steps": 50,
        "guidance_scale": 6.0,
        "use_benign": False,
        "save_every": 5,
        "fps": 16,
    }
    args = argparse.Namespace(**cfg)

    # train_adapter(args)
    eval_adapter(args)